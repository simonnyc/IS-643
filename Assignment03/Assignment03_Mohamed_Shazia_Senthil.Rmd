---
title: "DATA-643 Assignment - 03"
author:
- Mohamed Elmoudni
- Shazia Khan
- Senthil Dhanapal
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
---


```{r, echo = FALSE, warning=FALSE, message=FALSE}


if (!require("ggplot2",character.only = TRUE)) (install.packages("ggplot2",repos = "http://cran.us.r-project.org", dep=TRUE))
if (!require("recommenderlab",character.only = TRUE)) (install.packages("ggplot2",repos = "http://cran.us.r-project.org", dep=TRUE))
if (!require("reshape2",character.only = TRUE)) (install.packages("ggplot2",repos = "http://cran.us.r-project.org", dep=TRUE))
if (!require("knitr",character.only = TRUE)) (install.packages("ggplot2",repos = "http://cran.us.r-project.org", dep=TRUE))

library(recommenderlab)
library(reshape2)
library(ggplot2)
library(knitr)
library(recommenderlab)
library(recosystem)
library(SlopeOne)
library(SVDApproximation)
library(data.table)
library(RColorBrewer)
library(ggplot2)

```


\newpage



##Requirements:

### Project 03

The goal of this assignment is give you practice working with Singular Value Decomposition.
Your task is implement a matrix factorization method-such as singular value decomposition (SVD) or Alternating Least Squares (ALS)-in the context of a recommender system.
You may approach this in a large number of ways. You are welcome to start with an existing recommender system written by yourself or someone else (always citing your sources, so that you can be graded on what you added, not what you found).
Here is one example. Suppose you start with (or create) a collaborative filtering system against (a subset of) the MovieLens database or our toy dataset. You could create a content-based system, where you populate your item profiles by pulling text information for specific movies from a source like imdb, applying text processing techniques (like TF-IDF), then using SVD and topic modeling to create a set of features derived from the text.
An extra intermediate step could be to take text that was pre-classified, e.g. "fighting" or "singing" and build out two "explainable" features. SVD builds features that may or may not map neatly to movie genres or news topics.
You may work in a small group (2 or 3 people) on this assignment.

##Introduction 

###Recommendation Using SVD \newline
\

The goal of CF-based recommendation algorithms is to suggest new products or to predict the utility of a product for a customer, based on the customer's previous behavior and other similar customers 'opinions. However, these systems have some problems like sparsity, scalability, and synonymy. 
The weakness of CF algorithms for large, sparse databases led the researchers to alternative ways. 
In order to remove noise data from a large and sparse database, some dimensionality reduction techniques are proposed. Latent Semantic Indexing (LSI), which is a dimensionality reduction technique that used in information retrieval (IR), is a widely used technique to reduce the dimensionality of user-item ratings matrix. LSI, which uses singular value decomposition (SVD) as its underlying dimension reduction algorithm, maps nicely into the collaborative filtering recommender algorithm challenge 

#Toy Dataset 

First let's show an example of dimension reduction, consider the <user, movie> rating matrix A

```{r, echo = FALSE, warning=FALSE, message=FALSE}

User1 <- c(1, 5, 0, 5, 4)
User2<- c(5, 4, 4, 3, 2)
User3<- c(0, 4, 0, 0, 5)
User4<- c(4, 4, 1, 4, 0)
User5<- c(0, 4, 3, 5, 0)
User6<- c(2, 4, 3, 5, 3 )

A<- rbind(User1,User2, User3, User4, User5, User6)
colnames(A)<- c("Movie1","Movie2", "Movie3", "Movie4", "Movie5")
kable(A, caption = 'Original Matrix')

```

##Applying SVD to Toy matrix A

```{r, echo = FALSE, warning=FALSE, message=FALSE}

A.svd <- svd(A)
U<- matrix(A.svd$u,6,6)
kable(U, caption = 'SVD, U Matrix')
S<- diag(A.svd$d, 6,5)
kable(S, caption = 'Diagonal Matrix, S')
V_t<- t(A.svd$v)
#V_t
kable(V_t, caption = 'SVD, V transpose Matrix')

```


Matrix U (6x6), matrix S (6x5), and matrix V (5x5) are calculated. 
Now, we will collapse this matrix from a (6x5) space into a 2-Dimensional one. 
To do this, we simply take the first two columns of U, S and V. The end result


For a recommender system based on SVD, here is one very simple strategy: find the most similar user using the 2-Dimensional matrixes above with one of the similarity calculation algorithms and compare his/her items against that of the new user; take the items that the similar user has rated and the new user has not and return them for the new user. Similar to this, for a new item, find the most similar item using the 2-Dimensional matrixes above with one of the similarity calculation algorithms and compare the users rated similar item against the new item; take the users that rate similar item but not the new item and return the ratings for the new item.

##Testing using SVD in Toy dataset 

##Selecting k = 2

```{r, echo = FALSE, warning=FALSE, message=FALSE}
svd <- svd(A,nu=2,nv=2)
S <- diag(svd$d[1:2])
kable(svd$u %*% S %*% t(svd$v),  caption = 'SVD for k =2')

```

New user with rating: 0,0,2,0,4

```{r, echo = FALSE, warning=FALSE, message=FALSE}
b <-matrix(c(0,0,2,0,4,1),byrow=T, ncol=6)
S1 <- diag(1/svd$d[1:2])
b %*% svd$u %*% S1


```

##Selecting k = 3

```{r, echo = FALSE, warning=FALSE, message=FALSE}
svd <- svd(A,nu=3,nv=3)
S <- diag(svd$d[1:3])
kable(svd$u %*% S %*% t(svd$v),  caption = 'SVD for k =3')

```


### New user with rating: 0,0,2,0,4

```{r, echo = FALSE, warning=FALSE, message=FALSE}
b <-matrix(c(0,0,2,0,4,1),byrow=T, ncol=6)
S1 <- diag(1/svd$d[1:3])
b %*% svd$u %*% S1


```


# MovieLense dataset 

Now that we have a basic understanding on how to apply SVD in our toy data, let's apply it in the to bigger set such the Movie Lens dataset.  
We will be using the MovieLense dataset that comes with the recommenderlab package. 


```{r, echo = FALSE, warning=FALSE, message=FALSE}

set.seed(1)
data("MovieLense")


```


##Data Exploration




```{r, echo = FALSE, warning=FALSE, message=FALSE}

#set.seed(1)
mtx <- split_ratings(ratings_table = ratings, 
               proportion = c(0.7, 0.15, 0.15))

```


```{r, echo = FALSE, warning=FALSE, message=FALSE}

visualize_ratings(ratings_table = ratings, color_palett = "Dark2")

```



First,let's convert the data into sparse format. 

```{r, echo = FALSE, warning=FALSE, message=FALSE}

sparse_ratings <- sparseMatrix(i = ratings$user, j = ratings$item, x = ratings$rating, 
                               dims = c(length(unique(ratings$user)), length(unique(ratings$item))),  
                               dimnames = list(paste("u", 1:length(unique(ratings$user)), sep = ""), 
                                               paste("m", 1:length(unique(ratings$item)), sep = "")))
sparse_ratings[1:10, 1:10]
```


Creating a realRatingMatrix object from sparse matrix:


```{r, echo = FALSE, warning=FALSE, message=FALSE}
real_ratings <- new("realRatingMatrix", data = sparse_ratings)
real_ratings

```

##Model Creation without SVD

Creating the model:

```{r, echo = FALSE, warning=FALSE, message=FALSE}

model <- Recommender(real_ratings, method = "POPULAR", param=list(normalize = "center"))

```

Prediction of ratings for first 5 users:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
prediction <- predict(model, real_ratings[1:5], type="ratings")
as(prediction, "matrix")[,1:5]

```


## RMSE without SVD 

Calculation of RMSE

```{r, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(1)
e <- evaluationScheme(real_ratings, method="split", train=0.8, given=-5)
#5 ratings of 20% of users are excluded for testing

model <- Recommender(getData(e, "train"), "POPULAR")
prediction <- predict(model, getData(e, "known"), type="ratings")

rmse_popular <- calcPredictionAccuracy(prediction, getData(e, "unknown"))[1]
rmse_popular
```

Therefore the RMSE is `r rmse_popular ` 

## Model creation using SVD

```{r, echo = FALSE, warning=FALSE, message=FALSE}

model <- svd_build(mtx)

```

###Model tuning for different value of k (r in the R package)

```{r, echo = FALSE, warning=FALSE, message=FALSE}

model_tunes <- svd_tune(model, r = 2:50)
```


```{r, echo = FALSE, warning=FALSE, message=FALSE}
model_tunes$train_vs_valid
```

## RMSE using SVD

Creating RMSE using SVD:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
rmse_svd <- svd_rmse(model, r = model_tunes$r_best, rmse_type = c("test"))
rmse_svd

```

Therefore the RMSE usng SVD is `r rmse_svd ` 

# Conclusion

From the results above, we clearly see that the performance of the model on the MovieLens dataset using SVD is better than the model without SVD.  The RMSE using SVD is `r rmse_svd ` while the RMSE without SVD is `r rmse_popular ` .  However, choosing the value of k in the diagonal matrix S needs to be evaluated very carefully.   



\newpage

#Appendix A: DATA643 Assignment 03 R Code 
```{r code=readLines(knitr::purl('https://raw.githubusercontent.com/simonnyc/IS-643/master/Assignment02/Assignment02_Mohamed_Shazia_Senthil.Rmd', documentation = 0)), eval = FALSE}

```


